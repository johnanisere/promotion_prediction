{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Promotion.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johnanisere/promotion_prediction/blob/master/Promotion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLePQpJDMpFu",
        "colab_type": "code",
        "outputId": "6c9ed1d0-445f-4155-caf2-7310efeeeb73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder,StandardScaler\n",
        "from keras.utils import normalize\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Downloading CSV \n",
        "csv_file_url = \"https://firebasestorage.googleapis.com/v0/b/titor-staging.appspot.com/o/train.csv?alt=media&token=60305f3e-2273-4e5e-b5f5-61242abfa0a5\"\n",
        "csv_file = tf.keras.utils.get_file('data.csv', csv_file_url)\n",
        "\n",
        "# Downloading test CSV \n",
        "test_csv_file_url = \"https://firebasestorage.googleapis.com/v0/b/titor-staging.appspot.com/o/test.csv?alt=media&token=203cae0f-82d6-4fb7-9e5c-a5a9c23293fe\"\n",
        "test_csv_file = tf.keras.utils.get_file('test_data.csv', test_csv_file_url)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://firebasestorage.googleapis.com/v0/b/titor-staging.appspot.com/o/train.csv?alt=media&token=60305f3e-2273-4e5e-b5f5-61242abfa0a5\n",
            "5406720/5403244 [==============================] - 0s 0us/step\n",
            "Downloading data from https://firebasestorage.googleapis.com/v0/b/titor-staging.appspot.com/o/test.csv?alt=media&token=203cae0f-82d6-4fb7-9e5c-a5a9c23293fe\n",
            "2301952/2294317 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nw5hFPF9NAlU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing the dataset and removing irrelevant data\n",
        "dataset = pd.read_csv(csv_file).drop(['Gender','Channel_of_Recruitment','Year_of_birth','State_Of_Origin','Marital_Status','EmployeeNo'], axis=1)\n",
        "X = dataset.iloc[:, 0:12].values\n",
        "y = dataset.iloc[:, -1].values\n",
        "\n",
        "test_dataset = pd.read_csv(test_csv_file).drop(['Gender','Channel_of_Recruitment','Year_of_birth','State_Of_Origin','Marital_Status','EmployeeNo'], axis=1)\n",
        "test_X = test_dataset.iloc[:, :].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHBLxMsNmcdv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Taking care of missing data\n",
        "\n",
        "imputer = SimpleImputer(strategy='most_frequent')\n",
        "imputer = imputer.fit(X[:, 1:2])\n",
        "X[:, 1:2]=imputer.transform(X[:, 1:2])\n",
        "\n",
        "test_imputer = SimpleImputer(strategy='most_frequent')\n",
        "test_imputer = test_imputer.fit(test_X[:, 1:2])\n",
        "test_X[:, 1:2]=test_imputer.transform(test_X[:, 1:2])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2txajl4aejtL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encoding categorical data\n",
        "\n",
        "X[:, 0] = LabelEncoder().fit_transform(X[:, 0])\n",
        "X[:, 1] = LabelEncoder().fit_transform(X[:, 1])\n",
        "X[:, 8] = LabelEncoder().fit_transform(X[:, 8])\n",
        "X[:, 9] = LabelEncoder().fit_transform(X[:, 9])\n",
        "X[:, 10] = LabelEncoder().fit_transform(X[:, 10])\n",
        "X[:,-1] =  LabelEncoder().fit_transform(X[:, -1])\n",
        "onehotencoder = OneHotEncoder(handle_unknown='ignore')\n",
        "transformed = onehotencoder.fit_transform(X[:, :2]).toarray()\n",
        "X = np.concatenate([transformed, X[:, 3:]], axis=1)\n",
        "\n",
        "\n",
        "test_X[:, 0] = LabelEncoder().fit_transform(test_X[:, 0])\n",
        "test_X[:, 1] = LabelEncoder().fit_transform(test_X[:, 1])\n",
        "test_X[:, 8] = LabelEncoder().fit_transform(test_X[:, 8])\n",
        "test_X[:, 9] = LabelEncoder().fit_transform(test_X[:, 9])\n",
        "test_X[:, 10] = LabelEncoder().fit_transform(test_X[:, 10])\n",
        "test_X[:,-1] =  LabelEncoder().fit_transform(test_X[:, -1])\n",
        "onehotencoder = OneHotEncoder(handle_unknown='ignore')\n",
        "transformed = onehotencoder.fit_transform(test_X[:, :2]).toarray()\n",
        "test_X = np.concatenate([transformed, test_X[:, 3:]], axis=1)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjVHmIU4Rtvw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splitting the dataset into the Training set and Test set\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNGFKFLEpeF8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Feature Scaling\n",
        "\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "X_pred = sc.transform(test_X)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGQB9zxg5eUr",
        "colab_type": "code",
        "outputId": "1b4f83f5-83c7-4697-ed2c-7f380acefdd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "\n",
        "\n",
        "BATCH_SIZE=2\n",
        "EPOCHS=100\n",
        "\n",
        "# Initialising the ANN\n",
        "classifier=Sequential()\n",
        "\n",
        "# Adding the input layer \n",
        "classifier.add(Dense(activation='relu',units=11,kernel_initializer='uniform',input_dim=21))\n",
        "classifier.add(Dropout(rate=1))\n",
        "\n",
        "# # Adding the first hidden layer with dropout\n",
        "classifier.add(Dense(activation='relu',units=11,kernel_initializer='uniform'))\n",
        "classifier.add(Dropout(rate=1))\n",
        "\n",
        "\n",
        "# Adding the output layer\n",
        "classifier.add(Dense(activation='sigmoid',units=1,kernel_initializer='uniform'))\n",
        "\n",
        "# Compiling the ANN\n",
        "classifier.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "history = classifier.fit(X_train,y_train,validation_data=(X_test,y_test),batch_size=BATCH_SIZE,epochs=EPOCHS)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 30649 samples, validate on 7663 samples\n",
            "Epoch 1/100\n",
            "30649/30649 [==============================] - 77s 3ms/step - loss: 0.2200 - acc: 0.9213 - val_loss: 0.1934 - val_acc: 0.9362\n",
            "Epoch 2/100\n",
            "30649/30649 [==============================] - 77s 3ms/step - loss: 0.1915 - acc: 0.9353 - val_loss: 0.1871 - val_acc: 0.9379\n",
            "Epoch 3/100\n",
            "30649/30649 [==============================] - 76s 2ms/step - loss: 0.1868 - acc: 0.9371 - val_loss: 0.1827 - val_acc: 0.9401\n",
            "Epoch 4/100\n",
            " 9604/30649 [========>.....................] - ETA: 47s - loss: 0.1804 - acc: 0.9390"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fKPOITZhOYQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(EPOCHS)\n",
        "\n",
        "plt.figure(figsize=(24, 12))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.savefig('./foo.png')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WT1hlJ5PJbKD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_pred = sc.transform(test_X)\n",
        "y_pred = classifier.predict(X_pred)\n",
        "x=0\n",
        "prediction=[]\n",
        "true=[int(1)]\n",
        "false=[int(0)]\n",
        "for pred in y_pred:\n",
        "  if float(pred)*100>=49.5:\n",
        "    prediction.insert(x,true)\n",
        "    x+=1\n",
        "  else:\n",
        "    prediction.insert(x,false)\n",
        "    x+=1\n",
        "\n",
        "y_pred[:,:]=np.array(prediction,dtype=int)  \n",
        "employee_no = pd.read_csv(test_csv_file).iloc[:, 0:1].values\n",
        "result = np.concatenate([employee_no[:,:],np.array(prediction,dtype=int)], axis=1)\n",
        "\n",
        "submission = pd.DataFrame(result,columns=[\"EmployeeNo\",\"Promoted_or_Not\"]).to_csv(\"final_submission.csv\",index=False, index_label=False,)\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"final_submission.csv\")\n",
        "# files.download('foo.png')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}